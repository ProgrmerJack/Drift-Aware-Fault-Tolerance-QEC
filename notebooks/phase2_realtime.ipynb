{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b383d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Real-Time Drift Detection\n",
    "# ====================================\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Project imports\n",
    "from src.calibration import DriftCollector\n",
    "from src.probes import ProbeSuite, QubitSelector\n",
    "from src.qec import RepetitionCode, QECExperimentRunner\n",
    "from src.analysis import DriftErrorAnalyzer\n",
    "from src.utils import QPUBudgetTracker, load_experiment_results\n",
    "\n",
    "# IBM Quantum imports\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "print(\"Phase 2 imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a812f2",
   "metadata": {},
   "source": [
    "## 2.1 Load Baseline Results & Initialize Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ff71f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 1 baseline results for comparison\n",
    "baseline_results = load_experiment_results('../data/experiments/phase1_baseline_results.json')\n",
    "df_baseline = pd.read_parquet('../data/experiments/phase1_baseline.parquet')\n",
    "\n",
    "print(f\"Loaded {len(df_baseline)} baseline experiments\")\n",
    "print(f\"Baseline backend: {baseline_results['experiment_metadata']['backend']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize service and backend (use same backend as baseline)\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
    "baseline_backend_name = baseline_results['experiment_metadata']['backend']\n",
    "\n",
    "try:\n",
    "    backend = service.backend(baseline_backend_name)\n",
    "    print(f\"Using baseline backend: {backend.name}\")\n",
    "except:\n",
    "    backend = service.least_busy(simulator=False, operational=True, min_num_qubits=27)\n",
    "    print(f\"Baseline backend unavailable, using: {backend.name}\")\n",
    "\n",
    "# Initialize budget tracker\n",
    "budget_tracker = QPUBudgetTracker(total_budget_seconds=600)\n",
    "print(f\"Budget remaining: {budget_tracker.remaining_budget():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a348cf",
   "metadata": {},
   "source": [
    "## 2.2 Initialize Probe Suite\n",
    "\n",
    "The `ProbeSuite` implements lightweight 30-shot diagnostics:\n",
    "- **T1 Probe**: Single delay time to estimate T1\n",
    "- **Readout Probe**: |0⟩ and |1⟩ preparation + measurement\n",
    "- **RB Probe**: 2-3 Clifford sequences for gate fidelity estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dfb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize probe suite with 30 shots per probe\n",
    "probe_suite = ProbeSuite(\n",
    "    backend=backend,\n",
    "    shots_per_probe=30,\n",
    "    probes=['t1', 'readout', 'rb']\n",
    ")\n",
    "\n",
    "print(f\"Probe suite initialized with {len(probe_suite.probes)} probes\")\n",
    "print(f\"Estimated time per full probe: {probe_suite.estimate_time():.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f99d381",
   "metadata": {},
   "source": [
    "## 2.3 Collect Initial Calibration & Probe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current calibration snapshot\n",
    "drift_collector = DriftCollector(backend)\n",
    "initial_calibration = drift_collector.collect_calibration_snapshot()\n",
    "\n",
    "print(f\"Initial calibration collected at: {initial_calibration['timestamp']}\")\n",
    "\n",
    "# Identify candidate qubits for probing (top 20 from calibration)\n",
    "selector_static = QubitSelector(backend, strategy='static')\n",
    "candidate_qubits = selector_static.select_qubits(\n",
    "    n_qubits=20,\n",
    "    calibration_data=initial_calibration\n",
    ")['qubits']\n",
    "\n",
    "print(f\"Candidate qubits for probing: {candidate_qubits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc66d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run initial probes on candidate qubits\n",
    "print(\"Running initial probe suite...\")\n",
    "initial_probe_results = probe_suite.run_probes(\n",
    "    qubits=candidate_qubits,\n",
    "    budget_tracker=budget_tracker\n",
    ")\n",
    "\n",
    "print(f\"\\nProbe results collected for {len(initial_probe_results['qubit_data'])} qubits\")\n",
    "print(f\"Budget used so far: {budget_tracker.used_budget():.1f} seconds\")\n",
    "\n",
    "# Display probe results summary\n",
    "probe_df = pd.DataFrame(initial_probe_results['qubit_data'])\n",
    "print(\"\\nProbe Results Summary:\")\n",
    "print(probe_df[['qubit', 't1_probe', 'readout_error_probe', 'rb_fidelity_probe']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9649a99",
   "metadata": {},
   "source": [
    "## 2.4 Compare Static vs Real-Time Qubit Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f47214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static selection (from daily calibration)\n",
    "selector_static = QubitSelector(backend, strategy='static')\n",
    "static_selection_d5 = selector_static.select_qubits(\n",
    "    n_qubits=9,  # For distance-5 code\n",
    "    calibration_data=initial_calibration\n",
    ")\n",
    "\n",
    "# Real-time selection (from probe data)\n",
    "selector_rt = QubitSelector(backend, strategy='realtime')\n",
    "rt_selection_d5 = selector_rt.select_qubits(\n",
    "    n_qubits=9,\n",
    "    probe_data=initial_probe_results\n",
    ")\n",
    "\n",
    "print(\"Distance-5 Qubit Selection Comparison:\")\n",
    "print(f\"  Static (calibration): {static_selection_d5['qubits']}\")\n",
    "print(f\"  Real-time (probes):   {rt_selection_d5['qubits']}\")\n",
    "print(f\"  Overlap: {len(set(static_selection_d5['qubits']) & set(rt_selection_d5['qubits']))} qubits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ecf99f",
   "metadata": {},
   "source": [
    "## 2.5 Drift-Tracking Experiment Loop\n",
    "\n",
    "Run a series of experiments with periodic probe refreshes to track drift:\n",
    "1. Probe → Select qubits → Run QEC → Wait\n",
    "2. Repeat N times over experimental session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f64017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drift tracking parameters\n",
    "N_ITERATIONS = 5  # Number of probe-QEC cycles\n",
    "WAIT_BETWEEN_ITERATIONS = 600  # 10 minutes between iterations\n",
    "CODE_DISTANCE = 5\n",
    "N_SYNDROME_ROUNDS = 3\n",
    "SHOTS_PER_CIRCUIT = 1000\n",
    "\n",
    "# Storage for drift tracking\n",
    "drift_tracking_data = []\n",
    "rt_qec_results = []\n",
    "static_qec_results = []\n",
    "\n",
    "print(f\"Starting drift tracking experiment:\")\n",
    "print(f\"  Iterations: {N_ITERATIONS}\")\n",
    "print(f\"  Wait between: {WAIT_BETWEEN_ITERATIONS}s\")\n",
    "print(f\"  Code distance: {CODE_DISTANCE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6118074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main drift tracking loop\n",
    "runner = QECExperimentRunner(backend=backend, budget_tracker=budget_tracker)\n",
    "\n",
    "for iteration in range(N_ITERATIONS):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Iteration {iteration + 1}/{N_ITERATIONS}\")\n",
    "    print(f\"Time: {datetime.now(timezone.utc).isoformat()}\")\n",
    "    print(f\"Budget remaining: {budget_tracker.remaining_budget():.1f}s\")\n",
    "    \n",
    "    # Step 1: Run probes\n",
    "    print(\"Running probes...\")\n",
    "    probe_results = probe_suite.run_probes(\n",
    "        qubits=candidate_qubits,\n",
    "        budget_tracker=budget_tracker\n",
    "    )\n",
    "    \n",
    "    # Store drift data\n",
    "    drift_tracking_data.append({\n",
    "        'iteration': iteration,\n",
    "        'timestamp': probe_results['timestamp'],\n",
    "        'probe_data': probe_results['qubit_data']\n",
    "    })\n",
    "    \n",
    "    # Step 2: Select qubits using RT strategy\n",
    "    rt_qubits = selector_rt.select_qubits(\n",
    "        n_qubits=2 * CODE_DISTANCE - 1,\n",
    "        probe_data=probe_results\n",
    "    )['qubits']\n",
    "    \n",
    "    # Step 3: Run QEC with RT-selected qubits\n",
    "    print(f\"Running QEC with RT qubits: {rt_qubits}\")\n",
    "    rep_code_rt = RepetitionCode(distance=CODE_DISTANCE, qubits=rt_qubits)\n",
    "    circuit_rt = rep_code_rt.build_circuit(\n",
    "        n_syndrome_rounds=N_SYNDROME_ROUNDS,\n",
    "        initial_state='0',\n",
    "        measure_final=True\n",
    "    )\n",
    "    \n",
    "    job_id_rt = runner.submit_batch(\n",
    "        circuits=[circuit_rt],\n",
    "        metadata=[{'strategy': 'rt', 'iteration': iteration}],\n",
    "        shots=SHOTS_PER_CIRCUIT\n",
    "    )\n",
    "    \n",
    "    # Step 4: Run QEC with static-selected qubits (for comparison)\n",
    "    static_qubits = static_selection_d5['qubits']\n",
    "    print(f\"Running QEC with static qubits: {static_qubits}\")\n",
    "    rep_code_static = RepetitionCode(distance=CODE_DISTANCE, qubits=static_qubits)\n",
    "    circuit_static = rep_code_static.build_circuit(\n",
    "        n_syndrome_rounds=N_SYNDROME_ROUNDS,\n",
    "        initial_state='0',\n",
    "        measure_final=True\n",
    "    )\n",
    "    \n",
    "    job_id_static = runner.submit_batch(\n",
    "        circuits=[circuit_static],\n",
    "        metadata=[{'strategy': 'static', 'iteration': iteration}],\n",
    "        shots=SHOTS_PER_CIRCUIT\n",
    "    )\n",
    "    \n",
    "    # Collect results\n",
    "    results_rt = runner.collect_results(job_id_rt)\n",
    "    results_static = runner.collect_results(job_id_static)\n",
    "    \n",
    "    rt_qec_results.append({\n",
    "        'iteration': iteration,\n",
    "        'qubits': rt_qubits,\n",
    "        'counts': results_rt['counts'][0],\n",
    "        'timestamp': datetime.now(timezone.utc).isoformat()\n",
    "    })\n",
    "    \n",
    "    static_qec_results.append({\n",
    "        'iteration': iteration,\n",
    "        'qubits': static_qubits,\n",
    "        'counts': results_static['counts'][0],\n",
    "        'timestamp': datetime.now(timezone.utc).isoformat()\n",
    "    })\n",
    "    \n",
    "    # Wait before next iteration (except for last)\n",
    "    if iteration < N_ITERATIONS - 1:\n",
    "        print(f\"Waiting {WAIT_BETWEEN_ITERATIONS}s before next iteration...\")\n",
    "        time.sleep(WAIT_BETWEEN_ITERATIONS)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Drift tracking experiment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a40e9",
   "metadata": {},
   "source": [
    "## 2.6 Analyze Drift Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462a77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract drift time series for each qubit\n",
    "drift_analysis = []\n",
    "\n",
    "for qubit in candidate_qubits:\n",
    "    qubit_series = []\n",
    "    for entry in drift_tracking_data:\n",
    "        qubit_data = next((q for q in entry['probe_data'] if q['qubit'] == qubit), None)\n",
    "        if qubit_data:\n",
    "            qubit_series.append({\n",
    "                'iteration': entry['iteration'],\n",
    "                'timestamp': entry['timestamp'],\n",
    "                't1': qubit_data.get('t1_probe'),\n",
    "                'readout_error': qubit_data.get('readout_error_probe'),\n",
    "                'rb_fidelity': qubit_data.get('rb_fidelity_probe')\n",
    "            })\n",
    "    \n",
    "    if len(qubit_series) >= 2:\n",
    "        t1_values = [s['t1'] for s in qubit_series if s['t1']]\n",
    "        re_values = [s['readout_error'] for s in qubit_series if s['readout_error']]\n",
    "        \n",
    "        drift_analysis.append({\n",
    "            'qubit': qubit,\n",
    "            't1_mean': np.mean(t1_values) if t1_values else None,\n",
    "            't1_std': np.std(t1_values) if t1_values else None,\n",
    "            't1_drift_pct': (np.std(t1_values) / np.mean(t1_values) * 100) if t1_values else None,\n",
    "            'readout_mean': np.mean(re_values) if re_values else None,\n",
    "            'readout_std': np.std(re_values) if re_values else None\n",
    "        })\n",
    "\n",
    "df_drift = pd.DataFrame(drift_analysis)\n",
    "print(\"Drift Analysis Summary:\")\n",
    "print(df_drift.sort_values('t1_drift_pct', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8187be",
   "metadata": {},
   "source": [
    "## 2.7 Compare RT vs Static QEC Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.qec import SyndromeDecoder\n",
    "\n",
    "# Decode results and compute logical error rates\n",
    "decoder = SyndromeDecoder(distance=CODE_DISTANCE)\n",
    "\n",
    "rt_error_rates = []\n",
    "static_error_rates = []\n",
    "\n",
    "for rt_res, static_res in zip(rt_qec_results, static_qec_results):\n",
    "    # RT analysis\n",
    "    rt_analysis = decoder.analyze_results(\n",
    "        counts=rt_res['counts'],\n",
    "        initial_state='0',\n",
    "        n_rounds=N_SYNDROME_ROUNDS\n",
    "    )\n",
    "    rt_error_rates.append({\n",
    "        'iteration': rt_res['iteration'],\n",
    "        'strategy': 'RT',\n",
    "        'logical_error_rate': rt_analysis['logical_error_rate'],\n",
    "        'syndrome_error_rate': rt_analysis['syndrome_error_rate']\n",
    "    })\n",
    "    \n",
    "    # Static analysis\n",
    "    static_analysis = decoder.analyze_results(\n",
    "        counts=static_res['counts'],\n",
    "        initial_state='0',\n",
    "        n_rounds=N_SYNDROME_ROUNDS\n",
    "    )\n",
    "    static_error_rates.append({\n",
    "        'iteration': static_res['iteration'],\n",
    "        'strategy': 'Static',\n",
    "        'logical_error_rate': static_analysis['logical_error_rate'],\n",
    "        'syndrome_error_rate': static_analysis['syndrome_error_rate']\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(rt_error_rates + static_error_rates)\n",
    "print(\"RT vs Static Comparison:\")\n",
    "print(df_comparison.groupby('strategy')['logical_error_rate'].agg(['mean', 'std', 'min', 'max']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd47062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance test\n",
    "from scipy import stats\n",
    "\n",
    "rt_rates = [r['logical_error_rate'] for r in rt_error_rates]\n",
    "static_rates = [r['logical_error_rate'] for r in static_error_rates]\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(rt_rates, static_rates)\n",
    "\n",
    "print(f\"\\nStatistical Comparison:\")\n",
    "print(f\"  RT mean error rate: {np.mean(rt_rates):.4f} ± {np.std(rt_rates):.4f}\")\n",
    "print(f\"  Static mean error rate: {np.mean(static_rates):.4f} ± {np.std(static_rates):.4f}\")\n",
    "print(f\"  Improvement: {(np.mean(static_rates) - np.mean(rt_rates)) / np.mean(static_rates) * 100:.1f}%\")\n",
    "print(f\"  t-statistic: {t_stat:.3f}\")\n",
    "print(f\"  p-value: {p_value:.4f}\")\n",
    "print(f\"  Significant (p<0.05): {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9714a823",
   "metadata": {},
   "source": [
    "## 2.8 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00561ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Logical error rate over time (RT vs Static)\n",
    "ax1 = axes[0, 0]\n",
    "iterations = range(N_ITERATIONS)\n",
    "ax1.plot(iterations, rt_rates, 'o-', label='Real-Time', color='blue', markersize=8)\n",
    "ax1.plot(iterations, static_rates, 's--', label='Static', color='red', markersize=8)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Logical Error Rate')\n",
    "ax1.set_title('RT vs Static Selection Over Time')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: T1 drift for selected qubits\n",
    "ax2 = axes[0, 1]\n",
    "for qubit in candidate_qubits[:5]:  # Plot top 5 qubits\n",
    "    t1_series = []\n",
    "    for entry in drift_tracking_data:\n",
    "        qd = next((q for q in entry['probe_data'] if q['qubit'] == qubit), None)\n",
    "        if qd and qd.get('t1_probe'):\n",
    "            t1_series.append(qd['t1_probe'])\n",
    "    if t1_series:\n",
    "        ax2.plot(range(len(t1_series)), t1_series, 'o-', label=f'Q{qubit}')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('T1 (µs)')\n",
    "ax2.set_title('T1 Drift Over Experiment')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Error rate distribution comparison\n",
    "ax3 = axes[1, 0]\n",
    "ax3.boxplot([rt_rates, static_rates], labels=['RT', 'Static'])\n",
    "ax3.set_ylabel('Logical Error Rate')\n",
    "ax3.set_title('Error Rate Distribution')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Drift magnitude histogram\n",
    "ax4 = axes[1, 1]\n",
    "drift_pcts = df_drift['t1_drift_pct'].dropna()\n",
    "ax4.hist(drift_pcts, bins=10, edgecolor='black', alpha=0.7)\n",
    "ax4.axvline(drift_pcts.mean(), color='red', linestyle='--', label=f'Mean: {drift_pcts.mean():.1f}%')\n",
    "ax4.set_xlabel('T1 Drift (%)')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title('T1 Drift Magnitude Distribution')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/phase2_drift_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9459f390",
   "metadata": {},
   "source": [
    "## 2.9 Save Phase 2 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df1402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import save_experiment_results\n",
    "\n",
    "phase2_results = {\n",
    "    'drift_tracking_data': drift_tracking_data,\n",
    "    'rt_qec_results': rt_qec_results,\n",
    "    'static_qec_results': static_qec_results,\n",
    "    'drift_analysis': df_drift.to_dict('records'),\n",
    "    'comparison_stats': {\n",
    "        'rt_mean': float(np.mean(rt_rates)),\n",
    "        'rt_std': float(np.std(rt_rates)),\n",
    "        'static_mean': float(np.mean(static_rates)),\n",
    "        'static_std': float(np.std(static_rates)),\n",
    "        'improvement_pct': float((np.mean(static_rates) - np.mean(rt_rates)) / np.mean(static_rates) * 100),\n",
    "        't_statistic': float(t_stat),\n",
    "        'p_value': float(p_value)\n",
    "    },\n",
    "    'experiment_metadata': {\n",
    "        'phase': 2,\n",
    "        'n_iterations': N_ITERATIONS,\n",
    "        'wait_between': WAIT_BETWEEN_ITERATIONS,\n",
    "        'code_distance': CODE_DISTANCE,\n",
    "        'backend': backend.name,\n",
    "        'timestamp': datetime.now(timezone.utc).isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "save_experiment_results(phase2_results, '../data/experiments/phase2_drift_results.json')\n",
    "df_comparison.to_parquet('../data/experiments/phase2_comparison.parquet', index=False)\n",
    "\n",
    "print(\"Phase 2 results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a62b2a",
   "metadata": {},
   "source": [
    "## 2.10 Phase 2 Summary\n",
    "\n",
    "### Key Findings\n",
    "- **Drift magnitude**: Quantified intra-day drift in T1, T2, and readout errors\n",
    "- **RT improvement**: Real-time probe refresh shows X% improvement over static selection\n",
    "- **Probe overhead**: 30-shot probes add minimal QPU time (~Y seconds per iteration)\n",
    "\n",
    "### Next Steps (Phase 3)\n",
    "- Implement drift-aware qubit selection that predicts future drift\n",
    "- Use probe history to weight qubit selection\n",
    "- Integrate drift information into the decoder for adaptive-prior decoding"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
