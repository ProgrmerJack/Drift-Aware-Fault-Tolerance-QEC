{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32336b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Baseline QEC Experiments\n",
    "# ==================================\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Project imports\n",
    "from src.calibration import DriftCollector\n",
    "from src.probes import QubitSelector\n",
    "from src.qec import RepetitionCode, QECExperimentRunner\n",
    "from src.analysis import DriftErrorAnalyzer\n",
    "from src.utils import QPUBudgetTracker, load_calibration_snapshot\n",
    "\n",
    "# IBM Quantum imports\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "print(\"Phase 1 imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4311e59",
   "metadata": {},
   "source": [
    "## 1.1 Connect to IBM Quantum & Load Calibration Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize service and backend\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
    "\n",
    "# Select backend - prefer ibm_sherbrooke or similar 127-qubit device\n",
    "backend = service.least_busy(simulator=False, operational=True, min_num_qubits=27)\n",
    "print(f\"Selected backend: {backend.name}\")\n",
    "print(f\"Number of qubits: {backend.num_qubits}\")\n",
    "\n",
    "# Initialize drift collector and fetch latest calibration\n",
    "drift_collector = DriftCollector(backend)\n",
    "calibration_snapshot = drift_collector.collect_calibration_snapshot()\n",
    "\n",
    "print(f\"\\nCalibration snapshot collected at: {calibration_snapshot['timestamp']}\")\n",
    "print(f\"Qubits with data: {len(calibration_snapshot['qubit_properties'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4a793",
   "metadata": {},
   "source": [
    "## 1.2 Static Qubit Selection\n",
    "\n",
    "Use the `static` strategy to select qubits based on daily calibration metrics:\n",
    "- T1, T2 coherence times\n",
    "- Readout error rates\n",
    "- Single-qubit gate errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eb4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize qubit selector with static strategy\n",
    "selector = QubitSelector(backend, strategy='static')\n",
    "\n",
    "# Select qubits for different code distances\n",
    "# Distance d requires 2d-1 data qubits + d-1 ancillas = 3d-2 qubits total for repetition code\n",
    "qubit_selections = {}\n",
    "\n",
    "for distance in [3, 5, 7]:\n",
    "    n_qubits_needed = 2 * distance - 1  # Data qubits for repetition code\n",
    "    selected = selector.select_qubits(\n",
    "        n_qubits=n_qubits_needed,\n",
    "        calibration_data=calibration_snapshot\n",
    "    )\n",
    "    qubit_selections[distance] = selected\n",
    "    print(f\"Distance {distance}: Selected qubits {selected['qubits']}\")\n",
    "    print(f\"  Average T1: {selected['avg_t1']:.1f} µs\")\n",
    "    print(f\"  Average readout error: {selected['avg_readout_error']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae3188d",
   "metadata": {},
   "source": [
    "## 1.3 Baseline Repetition Code Experiments\n",
    "\n",
    "Run repetition code experiments with varying:\n",
    "- Code distances: d = 3, 5, 7\n",
    "- Number of syndrome rounds: r = 1, 2, 3, 4\n",
    "- Initial logical states: |0⟩L, |1⟩L, |+⟩L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8ab3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize budget tracker (10 min QPU time per 28-day window)\n",
    "budget_tracker = QPUBudgetTracker(total_budget_seconds=600)\n",
    "\n",
    "# Experiment parameters\n",
    "distances = [3, 5, 7]\n",
    "syndrome_rounds = [1, 2, 3, 4]\n",
    "logical_states = ['0', '1', '+']  # |0⟩L, |1⟩L, |+⟩L\n",
    "shots_per_circuit = 1000\n",
    "\n",
    "# Estimate QPU time needed\n",
    "n_circuits = len(distances) * len(syndrome_rounds) * len(logical_states)\n",
    "estimated_time = n_circuits * shots_per_circuit * 1e-3  # ~1ms per shot estimate\n",
    "print(f\"Estimated experiments: {n_circuits} circuits\")\n",
    "print(f\"Estimated QPU time: {estimated_time:.1f} seconds\")\n",
    "print(f\"Budget remaining: {budget_tracker.remaining_budget():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cbc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build repetition code circuits\n",
    "from src.qec import RepetitionCode\n",
    "\n",
    "experiment_circuits = []\n",
    "experiment_metadata = []\n",
    "\n",
    "for distance in distances:\n",
    "    qubits = qubit_selections[distance]['qubits']\n",
    "    rep_code = RepetitionCode(distance=distance, qubits=qubits)\n",
    "    \n",
    "    for n_rounds in syndrome_rounds:\n",
    "        for init_state in logical_states:\n",
    "            circuit = rep_code.build_circuit(\n",
    "                n_syndrome_rounds=n_rounds,\n",
    "                initial_state=init_state,\n",
    "                measure_final=True\n",
    "            )\n",
    "            experiment_circuits.append(circuit)\n",
    "            experiment_metadata.append({\n",
    "                'distance': distance,\n",
    "                'n_rounds': n_rounds,\n",
    "                'initial_state': init_state,\n",
    "                'qubits': qubits,\n",
    "                'strategy': 'static'\n",
    "            })\n",
    "\n",
    "print(f\"Built {len(experiment_circuits)} circuits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d4bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments using QECExperimentRunner\n",
    "runner = QECExperimentRunner(\n",
    "    backend=backend,\n",
    "    budget_tracker=budget_tracker\n",
    ")\n",
    "\n",
    "# Submit batch job\n",
    "print(\"Submitting baseline experiments to IBM Quantum...\")\n",
    "job_id = runner.submit_batch(\n",
    "    circuits=experiment_circuits,\n",
    "    metadata=experiment_metadata,\n",
    "    shots=shots_per_circuit\n",
    ")\n",
    "print(f\"Job submitted: {job_id}\")\n",
    "print(f\"Budget used: {budget_tracker.used_budget():.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c837ad3",
   "metadata": {},
   "source": [
    "## 1.4 Collect and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3670c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for job completion and collect results\n",
    "results = runner.collect_results(job_id, timeout=3600)  # 1 hour timeout\n",
    "\n",
    "print(f\"Job status: {results['status']}\")\n",
    "if results['status'] == 'DONE':\n",
    "    print(f\"Collected {len(results['counts'])} result sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148abb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze syndrome data and compute logical error rates\n",
    "from src.qec import SyndromeDecoder\n",
    "\n",
    "baseline_results = []\n",
    "\n",
    "for i, (counts, metadata) in enumerate(zip(results['counts'], experiment_metadata)):\n",
    "    decoder = SyndromeDecoder(distance=metadata['distance'])\n",
    "    \n",
    "    # Decode syndromes and compute logical error rate\n",
    "    analysis = decoder.analyze_results(\n",
    "        counts=counts,\n",
    "        initial_state=metadata['initial_state'],\n",
    "        n_rounds=metadata['n_rounds']\n",
    "    )\n",
    "    \n",
    "    baseline_results.append({\n",
    "        **metadata,\n",
    "        'logical_error_rate': analysis['logical_error_rate'],\n",
    "        'syndrome_error_rate': analysis['syndrome_error_rate'],\n",
    "        'total_shots': sum(counts.values()),\n",
    "        'timestamp': datetime.now(timezone.utc).isoformat()\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_baseline = pd.DataFrame(baseline_results)\n",
    "print(df_baseline.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208ee07e",
   "metadata": {},
   "source": [
    "## 1.5 Baseline Error Budget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1c155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute summary statistics by distance\n",
    "summary_by_distance = df_baseline.groupby('distance').agg({\n",
    "    'logical_error_rate': ['mean', 'std', 'min', 'max'],\n",
    "    'syndrome_error_rate': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print(\"Baseline Error Rates by Code Distance:\")\n",
    "print(\"=\" * 50)\n",
    "print(summary_by_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate with calibration metrics\n",
    "analyzer = DriftErrorAnalyzer()\n",
    "\n",
    "# Merge calibration data with results\n",
    "correlation_data = analyzer.correlate_calibration_with_errors(\n",
    "    calibration_snapshot=calibration_snapshot,\n",
    "    qec_results=df_baseline,\n",
    "    qubit_selections=qubit_selections\n",
    ")\n",
    "\n",
    "print(\"\\nCorrelation Analysis:\")\n",
    "print(f\"T1 vs Logical Error Rate: r = {correlation_data['t1_correlation']:.3f}\")\n",
    "print(f\"T2 vs Logical Error Rate: r = {correlation_data['t2_correlation']:.3f}\")\n",
    "print(f\"Readout Error vs Logical Error Rate: r = {correlation_data['readout_correlation']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1129436e",
   "metadata": {},
   "source": [
    "## 1.6 Visualize Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edf3151",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from src.analysis import plot_error_rates_by_distance, plot_error_budget_breakdown\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Logical error rate vs code distance\n",
    "plot_error_rates_by_distance(df_baseline, ax=axes[0])\n",
    "axes[0].set_title('Baseline Logical Error Rate vs Code Distance')\n",
    "\n",
    "# Plot 2: Error budget breakdown\n",
    "plot_error_budget_breakdown(correlation_data, ax=axes[1])\n",
    "axes[1].set_title('Error Budget Breakdown')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../data/figures/phase1_baseline_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82add029",
   "metadata": {},
   "source": [
    "## 1.7 Save Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import save_experiment_results\n",
    "\n",
    "# Save baseline results\n",
    "save_experiment_results(\n",
    "    results={\n",
    "        'baseline_df': df_baseline,\n",
    "        'calibration_snapshot': calibration_snapshot,\n",
    "        'qubit_selections': qubit_selections,\n",
    "        'correlation_data': correlation_data,\n",
    "        'experiment_metadata': {\n",
    "            'phase': 1,\n",
    "            'strategy': 'static',\n",
    "            'backend': backend.name,\n",
    "            'timestamp': datetime.now(timezone.utc).isoformat()\n",
    "        }\n",
    "    },\n",
    "    filepath='../data/experiments/phase1_baseline_results.json'\n",
    ")\n",
    "\n",
    "# Save DataFrame as parquet for efficient analysis\n",
    "df_baseline.to_parquet('../data/experiments/phase1_baseline.parquet', index=False)\n",
    "\n",
    "print(\"Phase 1 results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f544c45e",
   "metadata": {},
   "source": [
    "## 1.8 Phase 1 Summary\n",
    "\n",
    "### Key Findings\n",
    "- **Baseline logical error rates** established for d=3,5,7 repetition codes\n",
    "- **Error budget breakdown** quantifies contributions from gates, readout, and decoherence\n",
    "- **Calibration correlations** identify which metrics best predict QEC performance\n",
    "\n",
    "### Next Steps (Phase 2)\n",
    "- Implement real-time probe refresh to capture intra-day drift\n",
    "- Compare RT selection vs static selection under drift conditions\n",
    "- Quantify how stale calibration data impacts logical error rates"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
