{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b1d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "\n",
    "# Project imports\n",
    "from src.calibration import CalibrationCollector, DriftAnalyzer, collect_daily_snapshot\n",
    "from src.utils import QPUBudgetTracker, DataManager, setup_data_directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2af8b7c",
   "metadata": {},
   "source": [
    "## 1. Initialize IBM Quantum Service\n",
    "\n",
    "Connect to IBM Quantum using your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625c38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize service (assumes credentials are saved)\n",
    "# If first time, run: QiskitRuntimeService.save_account(channel=\"ibm_quantum\", token=\"YOUR_TOKEN\")\n",
    "\n",
    "try:\n",
    "    service = QiskitRuntimeService()\n",
    "    print(\"âœ… Connected to IBM Quantum\")\n",
    "    print(f\"Available backends: {len(service.backends())}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Connection failed: {e}\")\n",
    "    print(\"\\nTo set up credentials:\")\n",
    "    print('QiskitRuntimeService.save_account(channel=\"ibm_quantum\", token=\"YOUR_API_TOKEN\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03dc83d",
   "metadata": {},
   "source": [
    "## 2. Select Target Backend\n",
    "\n",
    "Choose a backend based on:\n",
    "- Availability in your region (Open Plan constraint)\n",
    "- Number of qubits (â‰¥127 for full experiments)\n",
    "- Dynamic circuit support (for mid-circuit measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46291ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available backends with properties\n",
    "backends = service.backends()\n",
    "\n",
    "print(\"Available backends:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for backend in backends:\n",
    "    config = backend.configuration()\n",
    "    num_qubits = config.num_qubits if hasattr(config, 'num_qubits') else 'N/A'\n",
    "    print(f\"{backend.name}: {num_qubits} qubits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c5961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select primary backend\n",
    "BACKEND_NAME = \"ibm_sherbrooke\"  # 127-qubit Eagle processor\n",
    "\n",
    "try:\n",
    "    backend = service.backend(BACKEND_NAME)\n",
    "    print(f\"âœ… Selected backend: {backend.name}\")\n",
    "    \n",
    "    config = backend.configuration()\n",
    "    print(f\"   Qubits: {config.num_qubits}\")\n",
    "    print(f\"   Basis gates: {config.basis_gates}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Backend not available: {e}\")\n",
    "    print(\"Try another backend from the list above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddc3cf",
   "metadata": {},
   "source": [
    "## 3. Setup Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data management\n",
    "dirs = setup_data_directories(\"../data\")\n",
    "\n",
    "print(\"Data directories created:\")\n",
    "for name, path in dirs.items():\n",
    "    print(f\"  {name}: {path}\")\n",
    "\n",
    "# Initialize budget tracker\n",
    "budget_tracker = QPUBudgetTracker(tracking_file=\"../data/qpu_budget.json\")\n",
    "print(f\"\\nðŸ“Š QPU Budget remaining: {budget_tracker.get_remaining_budget():.0f}s ({budget_tracker.get_remaining_budget()/60:.1f} min)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd19ae",
   "metadata": {},
   "source": [
    "## 4. Collect Calibration Snapshot\n",
    "\n",
    "This uses only the free backend properties API - no QPU time consumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a84f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize calibration collector\n",
    "collector = CalibrationCollector(data_dir=\"../data/calibration\")\n",
    "\n",
    "# Collect snapshot\n",
    "print(f\"Collecting calibration snapshot from {BACKEND_NAME}...\")\n",
    "snapshot_path = collect_daily_snapshot(service, BACKEND_NAME, collector)\n",
    "\n",
    "print(f\"âœ… Snapshot saved to: {snapshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aa8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and inspect snapshot\n",
    "snapshots = collector.load_snapshots(BACKEND_NAME)\n",
    "latest = snapshots[-1] if snapshots else None\n",
    "\n",
    "if latest:\n",
    "    print(f\"Latest snapshot: {latest['timestamp']}\")\n",
    "    print(f\"Calibration time: {latest['calibration_time']}\")\n",
    "    print(f\"Number of qubits: {latest['num_qubits']}\")\n",
    "    print(f\"Coupling map edges: {len(latest['coupling_map'])}\")\n",
    "    \n",
    "    # Show sample qubit properties\n",
    "    print(\"\\nSample qubit properties (qubit 0):\")\n",
    "    q0 = latest['qubits'].get('0', {})\n",
    "    for prop, data in q0.items():\n",
    "        print(f\"  {prop}: {data['value']:.6e} {data['unit']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bc692",
   "metadata": {},
   "source": [
    "## 5. Initial Drift Analysis\n",
    "\n",
    "Analyze available calibration data for drift patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b68344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize drift analyzer\n",
    "analyzer = DriftAnalyzer()\n",
    "\n",
    "# Generate drift report\n",
    "if len(snapshots) >= 2:\n",
    "    report = analyzer.generate_drift_report(snapshots, BACKEND_NAME)\n",
    "    \n",
    "    print(\"Drift Analysis Report\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Snapshots analyzed: {report['num_snapshots']}\")\n",
    "    print(f\"Date range: {report['date_range']['start']} to {report['date_range']['end']}\")\n",
    "    print(\"\\nRecommendations:\")\n",
    "    for rec in report['recommendations']:\n",
    "        print(f\"  â€¢ {rec}\")\n",
    "else:\n",
    "    print(\"Need at least 2 snapshots for drift analysis.\")\n",
    "    print(\"Run this notebook daily to build calibration history.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e191614a",
   "metadata": {},
   "source": [
    "## 6. Visualize Qubit Quality\n",
    "\n",
    "Create a heatmap of T1/T2 values across the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5373f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest:\n",
    "    # Extract T1 values\n",
    "    t1_values = []\n",
    "    t2_values = []\n",
    "    ro_errors = []\n",
    "    \n",
    "    for q_idx in range(latest['num_qubits']):\n",
    "        q_data = latest['qubits'].get(str(q_idx), {})\n",
    "        t1 = q_data.get('T1', {}).get('value', 0)\n",
    "        t2 = q_data.get('T2', {}).get('value', 0)\n",
    "        ro = q_data.get('readout_error', {}).get('value', 1)\n",
    "        \n",
    "        t1_values.append(t1 * 1e6 if t1 else 0)  # Convert to Î¼s\n",
    "        t2_values.append(t2 * 1e6 if t2 else 0)\n",
    "        ro_errors.append(ro)\n",
    "    \n",
    "    # Plot distributions\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    axes[0].hist(t1_values, bins=30, edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_xlabel('T1 (Î¼s)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].set_title(f'T1 Distribution ({BACKEND_NAME})')\n",
    "    \n",
    "    axes[1].hist(t2_values, bins=30, edgecolor='black', alpha=0.7, color='orange')\n",
    "    axes[1].set_xlabel('T2 (Î¼s)')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    axes[1].set_title(f'T2 Distribution ({BACKEND_NAME})')\n",
    "    \n",
    "    axes[2].hist(ro_errors, bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "    axes[2].set_xlabel('Readout Error')\n",
    "    axes[2].set_ylabel('Count')\n",
    "    axes[2].set_title(f'Readout Error Distribution ({BACKEND_NAME})')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../figures/phase0_qubit_quality.pdf', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"T1: mean={np.mean(t1_values):.1f}Î¼s, std={np.std(t1_values):.1f}Î¼s\")\n",
    "    print(f\"T2: mean={np.mean(t2_values):.1f}Î¼s, std={np.std(t2_values):.1f}Î¼s\")\n",
    "    print(f\"Readout Error: mean={np.mean(ro_errors):.4f}, std={np.std(ro_errors):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5658fd2c",
   "metadata": {},
   "source": [
    "## 7. Identify Best Qubits\n",
    "\n",
    "Rank qubits by quality for experiment planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d6696",
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest:\n",
    "    # Score each qubit\n",
    "    qubit_scores = []\n",
    "    \n",
    "    for q_idx in range(latest['num_qubits']):\n",
    "        q_data = latest['qubits'].get(str(q_idx), {})\n",
    "        \n",
    "        t1 = q_data.get('T1', {}).get('value', 0) or 0\n",
    "        t2 = q_data.get('T2', {}).get('value', 0) or 0\n",
    "        ro = q_data.get('readout_error', {}).get('value', 1) or 1\n",
    "        \n",
    "        # Simple scoring: higher T1/T2, lower readout error\n",
    "        score = (t1 * 1e6 / 100) + (t2 * 1e6 / 100) + (1 - ro) * 10\n",
    "        qubit_scores.append((q_idx, score, t1*1e6, t2*1e6, ro))\n",
    "    \n",
    "    # Sort by score\n",
    "    qubit_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"Top 20 Qubits by Quality Score:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Qubit':>6} {'Score':>8} {'T1(Î¼s)':>10} {'T2(Î¼s)':>10} {'RO Error':>10}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for q_idx, score, t1, t2, ro in qubit_scores[:20]:\n",
    "        print(f\"{q_idx:>6} {score:>8.2f} {t1:>10.1f} {t2:>10.1f} {ro:>10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4bfe3e",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "âœ… **Completed:**\n",
    "- Connected to IBM Quantum\n",
    "- Selected target backend\n",
    "- Set up data directories\n",
    "- Collected initial calibration snapshot\n",
    "- Identified high-quality qubits\n",
    "\n",
    "ðŸ“‹ **Next Steps:**\n",
    "1. **Run daily:** Execute cells 4-5 daily to build calibration history\n",
    "2. **Phase 1:** Once 7+ snapshots collected, proceed to probe suite validation\n",
    "3. **Budget check:** Current remaining: shown above\n",
    "\n",
    "âš ï¸ **Important:** This phase uses NO QPU time - only free calibration API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0824a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save phase completion status\n",
    "phase_status = {\n",
    "    \"phase\": 0,\n",
    "    \"completed_at\": datetime.now().isoformat(),\n",
    "    \"backend\": BACKEND_NAME,\n",
    "    \"snapshots_collected\": len(snapshots),\n",
    "    \"qpu_time_used\": 0,\n",
    "    \"ready_for_phase_1\": len(snapshots) >= 7\n",
    "}\n",
    "\n",
    "with open('../data/phase_status.json', 'w') as f:\n",
    "    json.dump(phase_status, f, indent=2)\n",
    "    \n",
    "print(\"Phase 0 status saved.\")\n",
    "print(f\"Ready for Phase 1: {phase_status['ready_for_phase_1']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
